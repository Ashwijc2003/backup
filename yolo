import torch
import cv2
import numpy as np
import RPi.GPIO as GPIO
import time
import os
import sys
sys.path.append(os.path.dirname(__file__))

from models.common import DetectMultiBackend
from utils.general import non_max_suppression, scale_coords
from utils.datasets import LoadStreams
from utils.augmentations import letterbox

# Setup GPIO
GPIO.setwarnings(False)
GPIO.setmode(GPIO.BCM)
GPIO.setup(17, GPIO.OUT)

# Load model
device = torch.device('cpu')
model = DetectMultiBackend('yolov5n.pt', device=device)
stride, names, pt = model.stride, model.names, model.pt
imgsz = (640, 640)

# Capture one frame from IP camera
cap = cv2.VideoCapture('http://192.168.0.105:8080/video')
time.sleep(2)
ret, frame = cap.read()
cap.release()

if not ret:
    print("Failed to get frame from camera.")
    exit()

img = letterbox(frame, imgsz, stride=stride, auto=True)[0]
img = img.transpose((2, 0, 1))[::-1]  # BGR to RGB
img = np.ascontiguousarray(img)
img = torch.from_numpy(img).to(device).float() / 255.0
img = img.unsqueeze(0) if img.ndimension() == 3 else img

pred = model(img, augment=False, visualize=False)
pred = non_max_suppression(pred, 0.25, 0.45, classes=None, agnostic=False)

# Process detection
for det in pred:
    if len(det):
        det[:, :4] = scale_coords(img.shape[2:], det[:, :4], frame.shape).round()
        for *xyxy, conf, cls in reversed(det):
            label = names[int(cls)]
            if 'drone' in label.lower():
                print("Drone detected!")
                GPIO.output(17, GPIO.HIGH)
                break





import urllib.request
import numpy as np
import cv2
import os
import torch
import RPi.GPIO as GPIO
from pathlib import Path
from models.common import DetectMultiBackend
from utils.datasets import LoadImages
from utils.general import non_max_suppression, scale_coords
from utils.torch_utils import select_device

# --- Setup GPIO ---
GPIO.setwarnings(False)
GPIO.setmode(GPIO.BCM)
GPIO.setup(18, GPIO.OUT)
GPIO.output(18, GPIO.LOW)

# --- Capture one frame from IP camera ---
url = 'http://192.168.0.105:8080/shot.jpg'
img_resp = urllib.request.urlopen(url)
img_np = np.array(bytearray(img_resp.read()), dtype=np.uint8)
frame = cv2.imdecode(img_np, -1)
cv2.imwrite("oneshot.jpg", frame)

# --- Load YOLOv5 model ---
weights = 'yolov5n.pt'
device = select_device('')
model = DetectMultiBackend(weights, device=device)
stride, names, pt = model.stride, model.names, model.pt
img_size = 640
dataset = LoadImages('oneshot.jpg', img_size=img_size, stride=stride, auto=pt)

# --- Inference ---
for path, img, im0s, vid_cap, s in dataset:
    img = torch.from_numpy(img).to(device)
    img = img.float() / 255.0
    img = img.unsqueeze(0) if img.ndimension() == 3 else img

    pred = model(img, augment=False, visualize=False)
    pred = non_max_suppression(pred, 0.5, 0.45, classes=None, agnostic=False)

    for det in pred:
        if det is not None and len(det):
            GPIO.output(18, GPIO.HIGH)  # ‚úÖ Trigger GPIO
            print("üéØ Object Detected!")
        else:
            GPIO.output(18, GPIO.LOW)
            print("‚ùå No object detected.")

# --- Cleanup ---
GPIO.cleanup()






# Fix the top of detect.py to import GPIO and set up pin 18
sed -i '1s/^/import RPi.GPIO as GPIO\nGPIO.setmode(GPIO.BCM)\nGPIO.setup(18, GPIO.OUT)\n/' ~/yolov5/detect.py

# Add GPIO trigger inside detection loop (after 'for det in dets:')
sed -i '/for det in dets:/a\        GPIO.output(18, GPIO.HIGH)' ~/yolov5/detect.py

# Move into yolov5 directory and run detection
cd ~/yolov5
python detect.py --source http://192.168.0.105:8080/video --weights yolov5n.pt --conf 0.5








# Fix GPIO import at top of detect.py (corrected typos: RPi, BCM, GPIO)
sed -i '1s/^/import RPi.GPIO as GPIO\nGPIO.setmode(GPIO.BCM)\nGPIO.setup(18, GPIO.OUT)\n/' ~/yolov5/detect.py

# Insert GPIO.output(18, GPIO.HIGH) after detection loop
sed -i '/for det in dets:/a\        GPIO.output(18, GPIO.HIGH)' ~/yolov5/detect.py

# Navigate to yolov5 directory and run detection with phone IP camera
cd ~/yolov5
python detect.py --source http://192.168.0.105:8080/video --weights yolov5n.pt --conf 0.5








# 1. Fix GPIO import at top of detect.py
sed -i '1s/^/import RPi.GPIO as GPIO\nGPIO.setmode(GPIO.BCM)\nGPIO.setup(18, GPIO.OUT)\n/' ~/yolov5/detect.py

# 2. Add HIGH trigger after detection
sed -i '/for det in dets:/a\ \ \ \ \ \ \ \ GPIO.output(18, GPIO.HIGH)' ~/yolov5/detect.py

# 3. Change to yolov5 directory and run detection
cd ~/yolov5
python detect.py --source http://192.168.0.105:8080/video --weights yolov5n.pt --conf 0.5









# Activate virtual environment
source ~/yolov5-env/bin/activate

# Fix GPIO import in detect.py and add output logic
sed -i '1i\import RPi.GPIO as GPIO\nGPIO.setmode(GPIO.BCM)\nGPIO.setup(18, GPIO.OUT)' ~/yolov5/detect.py
sed -i '/for det in dets:/a\ \ \ \ \ \ \ \ GPIO.output(18, GPIO.HIGH)' ~/yolov5/detect.py

# Run detection from phone IP camera stream
cd ~/yolov5
python detect.py --source http://192.168.0.105:8080/video --weights yolov5n.pt --conf 0.5










Great! Since the phone feed is now active again, and your Raspberry Pi is already set up with everything ‚Äî you just need to rerun the detection command.

‚úÖ Step to Re-Start YOLOv5 with Your Phone Camera:

Make sure you're inside your YOLOv5 folder and virtual environment. Then run:

source ~/yolov5-py39/bin/activate
cd ~/yolov5
python detect.py --source http://192.168.0.105:8080/video --weights yolov5n.pt --conf 0.5


---

üß† What‚Äôs Happening?

--source http://192.168.0.105:8080/video ‚Üí Live feed from your phone camera (IP Webcam)

--weights yolov5n.pt ‚Üí Using the lightweight YOLOv5 Nano model (good for Pi 3)

--conf 0.5 ‚Üí Confidence threshold 50%



---

üõ†Ô∏è If You Want to Run It Quickly Again Later:

Make a script:

nano run-detect.sh

Paste:

#!/bin/bash
source ~/yolov5-py39/bin/activate
cd ~/yolov5
python detect.py --source http://192.168.0.105:8080/video --weights yolov5n.pt --conf 0.5

Then make it executable:

chmod +x run-detect.sh

And run it anytime with:

./run-detect.sh

Let me know if you want to add GPIO trigger for drone or set this to run automatically on boot.









# 1. Install Python 3.9 and venv support
sudo apt update && sudo apt install -y python3.9 python3.9-venv python3.9-dev wget libopenblas-dev libjpeg-dev libpng-dev libavcodec-dev libavformat-dev libswscale-dev libgtk2.0-dev libgtk-3-dev

# 2. Create and activate Python 3.9 virtual environment
python3.9 -m venv yolov5-py39
source yolov5-py39/bin/activate

# 3. Upgrade pip and tools
pip install --upgrade pip setuptools wheel

# 4. Install core packages
pip install numpy matplotlib opencv-python

# 5. Download and install PyTorch prebuilt for Python 3.9 ARMv7
wget https://github.com/nmilosev/pytorch-arm-builds/releases/download/v1.12.0/torch-1.12.0-cp39-none-linux_armv7l.whl
pip install torch-1.12.0-cp39-none-linux_armv7l.whl

# 6. Clone YOLOv5 (if not already cloned)
git clone https://github.com/ultralytics/yolov5.git
cd yolov5

# 7. Install YOLOv5 dependencies
pip install -r requirements.txt

# 8. Run detection using your phone stream
python detect.py --source http://192.168.0.105:8080/video --weights yolov5n.pt --conf 0.5








Yes, üíØ ‚Äî you can install everything needed for YOLOv5 (including PyTorch) on your Raspberry Pi 3 in a single block of code.

Here‚Äôs a complete copy-paste script that:

1. Sets up a virtual environment


2. Installs dependencies


3. Downloads & installs PyTorch for ARM


4. Verifies everything is ready




---

‚úÖ One-Block Setup Script for YOLOv5 on Raspberry Pi 3

> üí° Paste this into your terminal as a single block (it handles everything).



sudo apt update && sudo apt install -y python3-pip python3-venv libopenblas-dev libblas-dev libatlas-base-dev libjpeg-dev libpng-dev libavcodec-dev libavformat-dev libswscale-dev libgtk2.0-dev libgtk-3-dev

# Create virtual environment
python3 -m venv yolov5-env
source yolov5-env/bin/activate

# Upgrade pip and tools
pip install --upgrade pip setuptools wheel

# Install core dependencies
pip install numpy matplotlib opencv-python

# Download and install PyTorch for Raspberry Pi 3 (ARMv7, Python 3.9)
wget https://github.com/nmilosev/pytorch-arm-builds/releases/download/v1.12.0/torch-1.12.0-cp39-none-linux_armv7l.whl
pip install torch-1.12.0-cp39-none-linux_armv7l.whl

# Optional: Verify torch installed correctly
python3 -c "import torch; print('‚úÖ PyTorch Version:', torch.__version__)"

# Clone YOLOv5 (if not done)
git clone https://github.com/ultralytics/yolov5
cd yolov5

# Install YOLOv5 requirements (some might already be installed)
pip install -r requirements.txt


---

‚ö†Ô∏è Make sure:

You are using Python 3.9 (check with python3 --version)

You‚Äôre on a Raspberry Pi 3, running Raspberry Pi OS Bookworm or Bullseye



---

After this, you can run:

sudo python3 detect.py --source http://192.168.0.105:8080/video --weights yolov5n.pt --conf 0.5

And GPIO should also work if you‚Äôve added the code!


---

Let me know if you want to turn GPIO high for specific objects only like 'drone', 'airplane', or 'bird', or if you want to run it headless (without monitor) in your college demo.











sudo python3 detect.py --source http://192.168.0.105:8080/video --weights yolov5n.pt --conf 0.5
You're almost there! The error you're seeing is because Debian Bookworm (your Raspberry Pi OS version) doesn't allow direct pip3 install into the system-wide Python environment by default.
udo python3 detect.py --source http://192.168.0.105:8080/video --weights yolov5n.pt --conf 0.5
Traceback (most recent call last):
  File "/home/ashwin/yolov5/detect.py", line 41, in <module>
    import torch
ModuleNotFoundError: No module named 'torch'

 

---

‚úÖ Here's how to fix it quickly:

üõ†Ô∏è Use a virtual environment ‚Äî this is the clean and safe method

Run these commands inside your ~/yolov5 folder:

# Step 1: Install the venv package if not already
sudo apt install python3-venv -y

# Step 2: Create a virtual environment
python3 -m venv yolov5-env

# Step 3: Activate the virtual environment
source yolov5-env/bin/activate

# Step 4: Now install the requirements safely inside the venv
pip install --upgrade pip
pip install -r requirements.txt

Now you're inside an isolated Python environment and can run YOLOv5 safely.


---

üöÄ Run Detection After Setup:

Once the install is done and you're still inside the venv, run:

python detect.py --source http://192.168.0.105:8080/video --weights yolov5n.pt --conf 0.5


---

‚ùó If You Exit or Reboot:

Next time, just do:

cd ~/yolov5
source yolov5-env/bin/activate
python detect.py --source http://192.168.0.105:8080/video --weights yolov5n.pt --conf 0.5

Let me know once you're done with this ‚Äî I‚Äôll help with GPIO next or help reduce delay.









Yes‚Äîthe GitHub link is absolutely working. You can access the official YOLOv5 repository and docs as follows:
loning into 'yolov5'...
remote: Enumerating objects: 17493, done.
remote: Counting objects: 100% (3/3), done.
remote: Compressing objects: 100% (3/3), done.
remote: Total 17493 (delta 1), reused 0 (delta 0), pack-reused 17490 (from 3)
Receiving objects: 100% (17493/17493), 16.59 MiB | 4.46 MiB/s, done.
Resolving deltas: 100% (11992/11992), done.
error: externally-managed-environment

√ó This environment is externally managed
‚ï∞‚îÄ> To install Python packages system-wide, try apt install
    python3-xyz, where xyz is the package you are trying to
    install.
    
    If you wish to install a non-Debian-packaged Python package,
    create a virtual environment using python3 -m venv path/to/venv.
    Then use path/to/venv/bin/python and path/to/venv/bin/pip. Make
    sure you have python3-full installed.
    
    For more information visit http://rptl.io/venv

note: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.
hint: See PEP 668 for the detailed specification.
bash: 192.168.0.105: No such file or directory
ashwin@Drone-detector:~/yolov5 $ 


---

‚úÖ YOLOv5 on GitHub

The main repository is fully available and up‚Äëto‚Äëdate:

ultralytics/yolov5 ‚Äî Official YOLOv5 code with model definitions, examples, and the detect.py script  


You‚Äôll find everything needed to clone, install, and run detection from live streams.


---

üìò Quickstart Guide

The quickstart instructions show how to get everything running fast:

1. Clone repository


2. Install dependencies


3. Run detect.py with your camera source  :



git clone https://github.com/ultralytics/yolov5
cd yolov5
pip install -r requirements.txt
python3 detect.py --source http://<your-phone-ip>:8080/video --weights yolov5n.pt --conf 0.5

It's straightforward, and your object will be tracked live with bounding boxes.


---

üîç Confirmation

The presence of the detect.py script, the README, and pip-installable models confirm the repo‚Äôs integrity and availability  


---

‚úÖ What You Should Do Next

Run those commands above on your Pi (or laptop if Pi is too slow).

Use --source to point to your phone‚Äôs stream.

Test with your drone as it flies.


Let me know once you've cloned and tested it‚Äîwe'll build motion/LED trigger integration after that!

